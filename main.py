import json
import os
import re
from dotenv import load_dotenv
from llm_client import get_completion, get_reasoning_completion
from web_ops import fetch_url_content
import notion_ops
# ğŸŒŸ å¼•å…¥æ–°çš„å‘é‡æ¨¡å—
import vector_ops 

try:
    from file_ops import read_pdf_content
except ImportError:
    read_pdf_content = None

load_dotenv()

# --- ğŸ› ï¸ æ ¸å¿ƒä¿®å¤ï¼šå…¨èƒ½è§£æå™¨ ---
def safe_json_parse(input_data, context=""):
    if not input_data:
        print(f"âŒ [Error] LLM returned EMPTY response for: {context}")
        return None
    if isinstance(input_data, dict): return input_data
    try:
        text = str(input_data).strip()
        clean_text = text.replace("```json", "").replace("```", "")
        start = clean_text.find("{")
        end = clean_text.rfind("}") + 1
        if start != -1 and end != -1: clean_text = clean_text[start:end]
        return json.loads(clean_text)
    except Exception as e:
        print(f"âŒ Parse Error: {e}")
        return None

# --- ğŸ§  Brain A: Classifier ---
def classify_intent(text):
    prompt = f"""
    Analyze the content type. First 800 chars: {text[:800]}
    Return JSON with "type":
    1. "Spanish": Language learning (Grammar, Vocab, Spanish videos).
    2. "Tech": AI, Coding, Engineering, Software, Hard Science.
    3. "Humanities": Politics, Economy, History, Philosophy, Social Science, News, Culture.
    """
    res = get_completion(prompt)
    return safe_json_parse(res, "Classify") or {"type": "Humanities"}

# --- ğŸ§  Brain B: Spanish Logic ---

# ğŸŒŸ [ç§»é™¤] æ—§çš„ check_topic_match å‡½æ•° (LLMç‰ˆ)
# ğŸŒŸ [æ–°å¢] æˆ‘ä»¬ç°åœ¨ç›´æ¥åœ¨ main_workflow é‡Œè°ƒç”¨ vector_ops.search_memory

def generate_spanish_content(text):
    print("ğŸš€ å¯åŠ¨ DeepSeek-R1 è¿›è¡Œè¯­è¨€åˆ†æ...")
    prompt = f"""
    You are a Spanish expert. Process this content: {text[:10000]}
    
    Output JSON (No Markdown):
    {{
        "title": "Note Title", 
        "category": "Vocab", 
        "summary": "Summary",
        "blocks": [
            {{ "type": "heading", "content": "1. Vocab" }},
            {{ "type": "table", "content": {{ "headers": ["ES","CN","Ex"], "rows": [["a","b","c"]] }} }}
        ]
    }}
    """
    content, reasoning = get_reasoning_completion(prompt)
    if reasoning: print(f"\nğŸ§  [R1 æ€è€ƒé“¾]:\n{reasoning[:200]}...\n")
    return safe_json_parse(content, "Spanish Content R1")

def decide_merge_strategy(new_text, structure, tables):
    prompt = f"""
    Merge Logic. Structure: {structure}. Tables: {json.dumps(tables)}. New: {new_text[:800]}
    Output JSON: {{ "action": "insert_row", "table_id": "...", "row_data": [...] }} OR {{ "action": "append_text" }}
    """
    return safe_json_parse(get_completion(prompt), "Merge Strategy") or {"action": "append_text"}

# --- ğŸ§  Brain C: General Logic ---
def process_general_knowledge(text):
    print("ğŸš€ å¯åŠ¨ DeepSeek-R1 è¿›è¡Œæ·±åº¦é˜…è¯»...")
    prompt = f"""
    Research Assistant. Analyze: {text[:15000]} 
    Output strictly JSON:
    {{
        "title": "Chinese Title", "summary": "Summary", "tags": ["Tag1"], "key_points": ["Point 1..."]
    }}
    """
    content, reasoning = get_reasoning_completion(prompt)
    if reasoning: print(f"\nğŸ§  [R1 æ€è€ƒé“¾]:\n{reasoning[:200]}...\n")
    return safe_json_parse(content, "General Knowledge R1")

# --- ğŸ© Main Workflow ---
def main_workflow(user_input=None, uploaded_file=None):
    processed_text = ""
    original_url = None
    
    if uploaded_file:
        if not read_pdf_content: raise Exception("Missing file_ops")
        print("ğŸ“‚ Reading PDF...")
        processed_text = read_pdf_content(uploaded_file)
    elif user_input:
        if user_input.strip().startswith("http"):
            original_url = user_input.strip()
            print(f"ğŸŒ Fetching URL: {original_url}")
            processed_text = fetch_url_content(original_url)
            processed_text = f"[Source] {original_url}\n{processed_text}"
        else:
            processed_text = user_input
    
    if not processed_text: raise Exception("Empty input")

    print("ğŸš¦ Routing...")
    intent = classify_intent(processed_text)
    content_type = intent.get('type', 'General')
    print(f"ğŸ‘‰ Type: {content_type}")

    current_page_id = None 

    # === ğŸŒŸ å‘é‡æŸ¥é‡ (Vector Retrieval) ===
    # ä¸å†æ¯æ¬¡å» Notion éå†æ‰€æœ‰æ ‡é¢˜ï¼Œè€Œæ˜¯æŸ¥æœ¬åœ°å‘é‡åº“ï¼Œæ¯«ç§’çº§å“åº”
    print("ğŸ§  Searching Knowledge Base (Vector)...")
    
    # æœç´¢æœ€ç›¸ä¼¼çš„1æ¡
    vector_match = vector_ops.search_memory(processed_text[:1000])
    
    if vector_match['match']:
        # === å‘½ä¸­æ—§ç¬”è®° ===
        print(f"ğŸ’¡ Vector Hit! Merging into: ã€Š{vector_match['title']}ã€‹")
        page_id = vector_match['page_id']
        current_page_id = page_id
        
        # æ— è®ºæ˜¯è¥¿è¯­è¿˜æ˜¯é€šç”¨ï¼Œåªè¦å‘½ä¸­äº†ï¼Œé€»è¾‘ç±»ä¼¼
        if content_type == 'Spanish':
            structure, tables = notion_ops.get_page_structure(page_id)
            if tables:
                strategy = decide_merge_strategy(processed_text, structure, tables)
                if strategy.get('action') == 'insert_row':
                    notion_ops.add_row_to_table(strategy['table_id'], strategy['row_data'])
                else:
                    data = generate_spanish_content(processed_text)
                    if data: notion_ops.append_to_page(page_id, data.get('summary'), data.get('blocks'))
            else:
                data = generate_spanish_content(processed_text)
                if data: notion_ops.append_to_page(page_id, data.get('summary'), data.get('blocks'))
        else:
            # é€šç”¨æ¨¡å¼åˆå¹¶
            data = process_general_knowledge(processed_text)
            if data: notion_ops.append_to_page(page_id, data.get('summary'), data.get('key_points'))
            
    else:
        # === æ–°ä¸»é¢˜ (Vector Miss) ===
        print("ğŸ†• New Topic Detected. Processing...")
        
        if content_type == 'Spanish':
            data = generate_spanish_content(processed_text)
            if data:
                current_page_id = notion_ops.create_study_note(
                    data.get('title'), 
                    data.get('category', 'General'), 
                    data.get('summary'), 
                    data.get('blocks'), 
                    original_url
                )
                # ğŸŒŸ å…³é”®ï¼šæ–°å»ºæˆåŠŸåï¼Œå­˜å…¥å‘é‡åº“
                if current_page_id:
                    vector_ops.add_memory(current_page_id, processed_text[:2000], data.get('title'), "Spanish")
        else:
            # é€šç”¨æ¨¡å¼
            target_db_id = notion_ops.DB_TECH_ID if content_type == 'Tech' else notion_ops.DB_HUMANITIES_ID
            data = process_general_knowledge(processed_text)
            if data:
                current_page_id = notion_ops.create_general_note(data, target_db_id, original_url)
                # ğŸŒŸ å…³é”®ï¼šæ–°å»ºæˆåŠŸåï¼Œå­˜å…¥å‘é‡åº“
                if current_page_id:
                    # å¯¹äºé€šç”¨çŸ¥è¯†ï¼Œå­˜æ‘˜è¦å¯èƒ½æ¯”å­˜å…¨æ–‡æ›´å‡†ï¼Œè¿™é‡Œå…ˆå­˜å‰2000å­—
                    vector_ops.add_memory(current_page_id, processed_text[:2000], data.get('title'), content_type)

    print("âœ… Processing Complete!")
    return True