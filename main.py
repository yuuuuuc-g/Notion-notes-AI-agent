import json
import os
import re
from dotenv import load_dotenv
from llm_client import get_completion, get_reasoning_completion # å¯¼å…¥ R1 å‡½æ•°
from web_ops import fetch_url_content
import notion_ops

try:
    from file_ops import read_pdf_content
except ImportError:
    read_pdf_content = None

load_dotenv()

# --- ğŸ› ï¸ æ ¸å¿ƒä¿®å¤ï¼šå…¨èƒ½è§£æå™¨ ---
def safe_json_parse(input_data, context=""):
    """
    å¸¦è°ƒè¯•åŠŸèƒ½çš„è§£æå™¨
    """
    if not input_data:
        print(f"âŒ [Error] LLM returned EMPTY response for: {context}")
        return None

    if isinstance(input_data, dict):
        return input_data
    
    try:
        text = str(input_data).strip()
        clean_text = text.replace("```json", "").replace("```", "")
        start = clean_text.find("{")
        end = clean_text.rfind("}") + 1
        if start != -1 and end != -1:
            clean_text = clean_text[start:end]
            
        return json.loads(clean_text)
    except json.JSONDecodeError as e:
        print(f"âŒ JSON Decode Error: {e}")
        return None
    except Exception as e:
        print(f"âŒ Unknown Parse Error: {e}")
        return None

# --- ğŸ§  Brain A: Classifier (ä¿æŒ V3ï¼Œå› ä¸ºå®ƒå¤Ÿå¿«) ---
def classify_intent(text):
    prompt = f"""
    Analyze the content type. First 800 chars: {text[:800]}
    Return JSON: {{ "type": "Spanish" }} OR {{ "type": "General" }}
    """
    res = get_completion(prompt)
    return safe_json_parse(res, "Classify") or {"type": "General"}

# --- ğŸ§  Brain B: Spanish Logic (å‡çº§ä¸º R1) ---
def check_topic_match(new_text, existing_pages):
    if not existing_pages: return {"match": False}
    titles_str = "\n".join([f"ID: {p['id']}, Title: {p['title']}" for p in existing_pages])
    prompt = f"""
    Library check. Existing: {titles_str}. New: {new_text[:800]}.
    Output JSON: {{ "match": true, "page_id": "...", "page_title": "..." }} OR {{ "match": false }}
    """
    res = get_completion(prompt) # æŸ¥é‡æ¯”è¾ƒç®€å•ï¼ŒV3 å¤Ÿç”¨
    return safe_json_parse(res, "Topic Match") or {"match": False}

def generate_spanish_content(text):
    """
    [R1 å‡çº§ç‰ˆ] ä½¿ç”¨æ¨ç†æ¨¡å‹æå–è¥¿è¯­çŸ¥è¯†
    """
    print("ğŸš€ å¯åŠ¨ DeepSeek-R1 è¿›è¡Œè¯­è¨€åˆ†æ...")
    prompt = f"""
    You are a Spanish teacher. Process this content: {text[:15000]}
    
    Output JSON (No Markdown):
    {{
        "title": "Title", 
        "category": "Vocab", 
        "summary": "Summary",
        "blocks": [
            {{ "type": "heading", "content": "1. Vocab" }},
            {{ "type": "table", "content": {{ "headers": ["ES","CN","Ex"], "rows": [["a","b","c"]] }} }}
        ]
    }}
    """
    # ğŸŒŸ è°ƒç”¨ R1
    content, reasoning = get_reasoning_completion(prompt)
    
    # æ‰“å°æ€è€ƒè¿‡ç¨‹ (å¯é€‰ï¼šå¦‚æœä½ æƒ³çœ‹å®ƒåœ¨æƒ³ä»€ä¹ˆ)
    print(f"\nğŸ§  [R1 æ€è€ƒé“¾]:\n{reasoning[:500]}...\n")
    
    return safe_json_parse(content, "Spanish Content R1")

def decide_merge_strategy(new_text, structure, tables):
    prompt = f"""
    Merge Logic. Structure: {structure}. Tables: {json.dumps(tables)}. New: {new_text[:800]}
    Output JSON: {{ "action": "insert_row", "table_id": "...", "row_data": [...] }} OR {{ "action": "append_text" }}
    """
    return safe_json_parse(get_completion(prompt), "Merge Strategy") or {"action": "append_text"}

# --- ğŸ§  Brain C: General Logic (å‡çº§ä¸º R1) ---
def process_general_knowledge(text):
    """
    [R1 å‡çº§ç‰ˆ] ä½¿ç”¨æ¨ç†æ¨¡å‹è¿›è¡Œæ·±åº¦é˜…è¯»
    """
    print("ğŸš€ å¯åŠ¨ DeepSeek-R1 è¿›è¡Œæ·±åº¦é˜…è¯»...")
    prompt = f"""
    You are a professional research assistant. 
    Analyze the following content deeply: 
    {text[:12000]} 
    
    **CRITICAL INSTRUCTION**: 
    1. Output strictly valid JSON.
    2. Do NOT summarize too briefly. 
    
    JSON Format:
    {{
        "title": "Chinese Title",
        "summary": "Chinese Summary (Detailed)",
        "tags": ["Tag1", "Tag2"],
        "key_points": [
            "Point 1: Detailed explanation...",
            "Point 2: Detailed explanation..."
        ]
    }}
    """
    
    # ğŸŒŸ è°ƒç”¨ R1
    content, reasoning = get_reasoning_completion(prompt)
    
    print(f"\nğŸ§  [R1 æ€è€ƒé“¾]:\n{reasoning[:500]}...\n")
    
    return safe_json_parse(content, "General Knowledge R1")

# --- ğŸ© Main Workflow ---
def main_workflow(user_input=None, uploaded_file=None):
    processed_text = ""
    original_url = None
    
    # 1. è·å–è¾“å…¥
    if uploaded_file:
        if not read_pdf_content:
            raise Exception("âŒ file_ops.py not found or failed to import.")
        print("ğŸ“‚ Reading PDF...")
        processed_text = read_pdf_content(uploaded_file)
        if not processed_text:
            raise Exception("âŒ PDF is empty or unreadable.")
    elif user_input:
        if user_input.strip().startswith("http"):
            original_url = user_input.strip()
            print(f"ğŸŒ Fetching URL: {original_url}")
            processed_text = fetch_url_content(original_url)
            processed_text = f"[Source] {original_url}\n{processed_text}"
        else:
            processed_text = user_input
    
    if not processed_text:
        raise Exception("âš ï¸ No input provided.")

    # 2. è·¯ç”±
    print("ğŸš¦ Routing content...")
    intent = classify_intent(processed_text)
    content_type = intent.get('type', 'General')
    print(f"ğŸ‘‰ Type: {content_type}")

    # 3. å¤„ç†æµç¨‹
    if content_type == 'Spanish':
        print("ğŸ‡ªğŸ‡¸ Spanish Mode...")
        existing_titles = notion_ops.get_all_page_titles(notion_ops.DB_SPANISH_ID)
        match = check_topic_match(processed_text, existing_titles)
        
        if match.get('match'):
            print(f"ğŸ’¡ Merging into: {match.get('page_title')}")
            structure, tables = notion_ops.get_page_structure(match.get('page_id'))
            if tables:
                strategy = decide_merge_strategy(processed_text, structure, tables)
                if strategy.get('action') == 'insert_row':
                    notion_ops.add_row_to_table(strategy['table_id'], strategy['row_data'])
                    return 
            
            data = generate_spanish_content(processed_text)
            if data:
                notion_ops.append_to_page(match.get('page_id'), data.get('summary'), data.get('blocks'))
        else:
            print("ğŸ†• Creating New Spanish Note...")
            data = generate_spanish_content(processed_text)
            if data:
                res = notion_ops.create_study_note(data.get('title'), data.get('category', 'General'), data.get('summary'), data.get('blocks'), original_url)
                if not res: raise Exception("Failed to create Notion page.")

    else:
        print("ğŸŒ General Knowledge Mode...")
        existing_titles = notion_ops.get_all_page_titles(notion_ops.DB_GENERAL_ID)
        match = check_topic_match(processed_text, existing_titles)
        
        print("ğŸ§  Generating notes (Deep Analysis)...")
        data = process_general_knowledge(processed_text)
        
        if not data:
            raise Exception("âŒ AI failed to generate valid JSON notes.")

        if match.get('match'):
            print(f"ğŸ’¡ Topic Exists! Merging into: ã€Š{match.get('page_title')}ã€‹")
            notion_ops.append_to_page(match.get('page_id'), data.get('summary'), data.get('key_points'))
        else:
            print("ğŸ†• Creating General Note...")
            res = notion_ops.create_general_note(data, original_url)
            if not res: raise Exception("Failed to write to Notion (Check DB ID).")

    print("âœ… Processing Complete!")
    