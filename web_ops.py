import requests
import re
import json
import yt_dlp

def get_video_id(url):
    """ä» YouTube URL ä¸­æå–è§†é¢‘ ID"""
    patterns = [
        r"(?:v=|\/)([0-9A-Za-z_-]{11}).*",
        r"(?:youtu\.be\/)([0-9A-Za-z_-]{11})",
        r"(?:embed\/)([0-9A-Za-z_-]{11})"
    ]
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    return None

def fetch_youtube_content(url):
    """
    ä¸“é—¨å¤„ç† YouTube è§†é¢‘ï¼šä½¿ç”¨ yt-dlp
    """
    print(f"ğŸ“º YouTube video detected, starting yt-dlp engine...")
    
    # é…ç½® yt-dlpï¼šä¸ä¸‹è½½è§†é¢‘ï¼Œåªè·å–å…ƒæ•°æ®
    ydl_opts = {
        'skip_download': True,  # ä¸ä¸‹è½½è§†é¢‘
        'quiet': True,          # å®‰é™æ¨¡å¼ï¼Œå°‘è¾“å‡ºåºŸè¯
        'no_warnings': True,
    }

    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            # 1. æå–è§†é¢‘ä¿¡æ¯
            info = ydl.extract_info(url, download=False)
            
            # 2. å¯»æ‰¾å­—å¹•
            # yt-dlp æŠŠå­—å¹•åˆ†ä¸¤ç±»ï¼šsubtitles (äººå·¥ä¸Šä¼ ) å’Œ automatic_captions (è‡ªåŠ¨ç”Ÿæˆ)
            # æˆ‘ä»¬ä¼˜å…ˆæ‰¾äººå·¥çš„ï¼Œæ²¡æœ‰å†æ‰¾è‡ªåŠ¨çš„
            subtitles = info.get('subtitles', {})
            auto_captions = info.get('automatic_captions', {})
            
            # å®šä¹‰æˆ‘ä»¬æƒ³è¦çš„è¯­è¨€ä¼˜å…ˆçº§
            langs = ['es', 'en', 'zh-Hans', 'zh-Hant']
            
            target_url = None
            found_lang = None

            # ç­–ç•¥ï¼šå…ˆåœ¨ã€äººå·¥å­—å¹•ã€‘é‡Œæ‰¾
            for lang in langs:
                if lang in subtitles:
                    # å¯»æ‰¾ json3 æ ¼å¼ (æœ€å®¹æ˜“è§£æ)ï¼Œæ²¡æœ‰å°±æ‹¿ç¬¬ä¸€ä¸ª
                    for fmt in subtitles[lang]:
                        if fmt['ext'] == 'json3':
                            target_url = fmt['url']
                            found_lang = lang
                            break
                    if target_url: break
            
            # ç­–ç•¥ï¼šå¦‚æœæ²¡æ‰¾åˆ°ï¼Œå»ã€è‡ªåŠ¨å­—å¹•ã€‘é‡Œæ‰¾
            if not target_url:
                for lang in langs:
                    if lang in auto_captions:
                        for fmt in auto_captions[lang]:
                            if fmt['ext'] == 'json3':
                                target_url = fmt['url']
                                found_lang = lang + " (Auto)"
                                break
                        if target_url: break
            
            # ç­–ç•¥ï¼šå¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œå°±éšä¾¿æ‹¿ä¸€ä¸ªè‡ªåŠ¨å­—å¹•ï¼ˆé€šå¸¸æ˜¯åŸå£°çš„è‡ªåŠ¨ç”Ÿæˆï¼‰
            if not target_url and auto_captions:
                first_lang = list(auto_captions.keys())[0]
                target_url = auto_captions[first_lang][0]['url']
                found_lang = first_lang + " (Fallback)"

            if not target_url:
                return f"âš ï¸ No subtitles found for this video...\nè§†é¢‘æ ‡é¢˜ï¼š{info.get('title')}\nç®€ä»‹ï¼š{info.get('description')}"

            # 3. ä¸‹è½½å¹¶è§£æå­—å¹•æ•°æ®
            print(f"âœ… Subtitle source locked({found_lang})ï¼Œdownloading...")
            # yt-dlp çš„ json3 æ ¼å¼éå¸¸æ ‡å‡†ï¼Œç›´æ¥è¯·æ±‚ URL å³å¯
            subs_json = requests.get(target_url).json()
            
            # 4. æ‹¼æ¥å­—å¹•æ–‡æœ¬
            # json3 ç»“æ„: {'events': [{'tStartMs': 1000, 'dDurationMs': 2000, 'segs': [{'utf8': 'æ–‡æœ¬'}]}]}
            full_text = []
            if 'events' in subs_json:
                for event in subs_json['events']:
                    if 'segs' in event:
                        # æŠŠè¿™ä¸€å¥é‡Œçš„æ‰€æœ‰ç‰‡æ®µæ‹¼èµ·æ¥
                        line = "".join([seg['utf8'] for seg in event['segs'] if 'utf8' in seg])
                        if line.strip() and line != '\n':
                            full_text.append(line.strip())
            
            final_text = "\n".join(full_text)
            
            # é•¿åº¦æˆªæ–­ä¿æŠ¤
            if len(final_text) > 15000:
                final_text = final_text[:15000] + "\n...(å­—å¹•è¿‡é•¿å·²æˆªæ–­)"
                
            return f"ã€æ¥æºï¼šYouTube å­—å¹• (ç”± yt-dlp æå– - {found_lang})ã€‘\n{final_text}"

    except Exception as e:
        print(f"âŒ yt-dlp extraction failed: {e}")
        # æœ€åçš„ä¿åº•ï¼šè¿˜æ˜¯å»æŠ“ç½‘é¡µæ–‡å­—
        return fetch_url_content_fallback(url)

def fetch_url_content_fallback(url):
    """Jina å¤‡ç”¨æŠ“å–"""
    jina_url = f"https://r.jina.ai/{url}"
    try:
        response = requests.get(jina_url, timeout=30)
        return f"ã€æ¥æºï¼šç½‘é¡µæŠ“å–ï¼ˆæ— å­—å¹•ï¼‰ã€‘\n{response.text[:10000]}"
    except Exception as e:
        return f"âŒ æŠ“å–å½»åº•å¤±è´¥: {e}"

def fetch_url_content(url):
    print(f"ğŸŒ Web Analyst is analyzing link: {url} ...")
    if "youtube.com" in url or "youtu.be" in url:
        return fetch_youtube_content(url)
    return fetch_url_content_fallback(url)