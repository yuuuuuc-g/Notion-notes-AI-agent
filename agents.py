import json
from llm_client import get_completion, get_reasoning_completion
import notion_ops
import vector_ops

try:
    from file_ops import read_pdf_content
except ImportError:
    read_pdf_content = None


# =========================================================
# Utilities
# =========================================================
def safe_json_parse(input_data, context=""):
    if not input_data:
        return None
    if isinstance(input_data, dict):
        return input_data
    try:
        text = str(input_data).strip()
        # Clean potential markdown code blocks
        clean = text.replace("```json", "").replace("```", "")
        start = clean.find("{")
        end = clean.rfind("}") + 1
        if start != -1 and end != -1:
            clean = clean[start:end]
        return json.loads(clean)
    except Exception as e:
        print(f"âŒ [{context}] JSON parse error:", e)
        return None


# =========================================================
# Researcher Agent
# =========================================================
class ResearcherAgent:
    def __init__(self):
        print("ğŸ•µï¸â€â™‚ï¸ Researcher Agent initialized.")
        
    def merge_content(self, old_text: str, new_input: str) -> dict:
        """
        åˆå¹¶æ—§ç¬”è®°å†…å®¹å’Œæ–°è¾“å…¥å†…å®¹
        
        å‚æ•°:
            old_text: ç°æœ‰ç¬”è®°çš„æ–‡æœ¬å†…å®¹
            new_input: æ–°çš„è¾“å…¥å†…å®¹
        
        è¿”å›:
            dict: åˆå¹¶åçš„è‰ç¨¿ï¼ŒåŒ…å« title, summary, markdown_body, tags
        """
        print("âš—ï¸ Researcher merging content...")
        prompt = f"""
        Act as a Knowledge Editor. 
        Task: Merge the NEW INPUT into the EXISTING NOTE.
        
        EXISTING NOTE:
        {old_text[:5000]}
        
        NEW INPUT:
        {new_input[:5000]}
        
        Output JSON (Markdown):
        {{
            "title": "Combined Title",
            "summary": "Summary of changes",
            "markdown_body": "# Title\\n\\nMerged content...",
            "tags": ["tag1", "tag2"]
        }}
        """
        res, _ = get_reasoning_completion(prompt)
        return safe_json_parse(res, "Merge Draft")

    def analyze_intent(self, text: str) -> dict:
        if text.strip().startswith("âŒ Error"):
            print("ğŸ›‘ Error detected in content, skipping analysis.")
            return {"intent": "Error", "category": "Error"}

        prompt = f"""
        Analyze the user input to determine the INTENT and CATEGORY.

        Input Preview: {text[:800]}

        DEFINITIONS:
        1. **intent**:
           - "save_note": The user wants to save, record, summarize, extract, or write down information.
           - "query_knowledge": The user is asking a question or looking for specific information.

        2. **category**:
           - "Spanish" (Language learning)
           - "Tech" (Programming, AI, Engineering)
           - "Humanities" (History, Economics, Philosophy, General)

        RETURN STRICT JSON:
        {{
            "intent": "save_note" | "query_knowledge",
            "category": "Spanish" | "Tech" | "Humanities"
        }}
        """
        res = get_completion(prompt)
        
        parsed = safe_json_parse(res, "Intent Analysis")
        if not parsed:
            return {"intent": "save_note", "category": "Humanities"}
        
        # Compatibility fix
        if "type" in parsed and "category" not in parsed:
            parsed["category"] = parsed["type"]
            
        return parsed

    def consult_memory(self, text: str, domain: str = None) -> dict:
        """
        ä»å‘é‡æ•°æ®åº“ä¸­æŸ¥è¯¢ç›¸å…³è®°å¿†
        
        å‚æ•°:
            text: æŸ¥è¯¢æ–‡æœ¬
            domain: é¢†åŸŸè¿‡æ»¤å™¨ï¼ŒNone æˆ– "All" è¡¨ç¤ºæœç´¢æ‰€æœ‰é¢†åŸŸ
        
        è¿”å›:
            dict: æŸ¥è¯¢ç»“æœï¼ŒåŒ…å« matchã€page_idã€title ç­‰å­—æ®µ
        """
        category_filter = None if domain == "All" else domain
        print(f"ğŸ§  Memory search (Filter: {category_filter})...")
        return vector_ops.search_memory(text[:1000], category_filter=category_filter)

    def merge_content(self, old_text: str, new_input: str) -> dict:
        """
        æ ¹æ®æ–‡æœ¬å†…å®¹ç”Ÿæˆç»“æ„åŒ–è‰ç¨¿
        
        å‚æ•°:
            text: åŸå§‹æ–‡æœ¬å†…å®¹
            category: å†…å®¹åˆ†ç±»ï¼Œå¯é€‰å€¼ "Spanish" | "Tech" | "Humanities"ï¼ˆé»˜è®¤ä¸º "Humanities"ï¼‰
            error_context: é”™è¯¯ä¸Šä¸‹æ–‡ï¼Œç”¨äºé‡è¯•æ—¶æä¾›ä¹‹å‰çš„é”™è¯¯ä¿¡æ¯
        
        è¿”å›:
            dict: åŒ…å« title, summary, markdown_body, tags ç­‰å­—æ®µçš„è‰ç¨¿å­—å…¸
        """
        if text.strip().startswith("âŒ Error"):
            return {
                "title": "âš ï¸ Content Fetch Failed",
                "summary": "Unable to retrieve content.",
                "markdown_body": f"# Error Details\n\n> {text}",
                "category": "Error",
                "tags": ["Error"]
            }

        current_error = error_context
        
        for attempt in range(3):
            print(f"ğŸ”„ Draft Generation Attempt {attempt + 1}/3...")
            
            err_msg_block = ""
            if current_error:
                err_msg_block = f"\n\n--- PREVIOUS ERROR ---\n{current_error}\n----------------------\n"

            if category == "Spanish":
                prompt = f"""
                You are a Spanish teacher.
                {err_msg_block}
                Input: {text[:20000]}
                
                Analyze the content and Output STRICT JSON.
                LANGUAGE: SIMPLIFIED CHINESE.
                FORMAT: Markdown.
                
                JSON SCHEMA:
                {{
                    "title": "string",
                    "category": "Grammar | Vocabulary | Culture",
                    "summary": "string",
                    "markdown_body": "# Title\\nContent...",
                    "tags": ["string"]
                }}
                """
                tag = "Spanish Draft"
            else: 
                prompt = f"""
                You are a professional research editor.
                {err_msg_block}
                Input: {text[:20000]}

                Analyze and output STRICT JSON.
                LANGUAGE: SIMPLIFIED CHINESE.
                
                JSON SCHEMA:
                {{
                  "title": "string",
                  "summary": "string",
                  "markdown_body": "# Title\\nContent...",
                  "tags": ["string"],
                  "category": "string"
                }}
                """
                tag = "General Draft"

            content, _ = get_reasoning_completion(prompt)
            draft = safe_json_parse(content, tag)
            
            if draft and isinstance(draft, dict) and draft.get("markdown_body"):
                if not isinstance(draft.get("summary"), str):
                    draft["summary"] = draft.get("markdown_body", "")[:300]
                if not isinstance(draft.get("title"), str):
                    draft["title"] = "Untitled"
                if not isinstance(draft.get("tags"), list):
                    draft["tags"] = []
                
                print(f"âœ… Attempt {attempt + 1} Success.")
                return draft
            
            print(f"âš ï¸ Attempt {attempt + 1} Failed.")
            current_error = f"JSON Parsing Failed. Raw output start: {content[:500]}..."

        print("âŒ All attempts failed.")
        return {
            "title": "Untitled (Parse Error)",
            "summary": "Parsing failed.",
            "markdown_body": f"# Original Content\n\n{text[:3000]}",
            "tags": ["Error"],
            "category": "Uncategorized"
        }

# =========================================================
# Editor Agent
# =========================================================
class EditorAgent:
    def __init__(self):
        print("âœï¸ Editor Agent initialized.")

    def publish(
        self,
        draft: dict,
        intent_type: str,
        memory_match: dict,
        raw_text: str,
        original_url: str = None,
        *,
        domain: str = None,
        database_id: str = None,
    ) -> dict:
        """
        å°†è‰ç¨¿å‘å¸ƒåˆ° Notion
        
        å‚æ•°:
            draft: è‰ç¨¿å­—å…¸ï¼ŒåŒ…å« title, summary, markdown_body, tags
            intent_type: æ„å›¾ç±»å‹ï¼ˆç›®å‰æœªåœ¨é€»è¾‘ä¸­ä½¿ç”¨ï¼‰
            memory_match: è®°å¿†åŒ¹é…ç»“æœï¼ˆåœ¨æ–°æµç¨‹ä¸­é€šå¸¸ä¸º Noneï¼Œåˆå¹¶é€»è¾‘åœ¨ workflow ä¸­å¤„ç†ï¼‰
            raw_text: åŸå§‹æ–‡æœ¬
            original_url: åŸå§‹ URLï¼ˆå¯é€‰ï¼‰
            domain: é¢†åŸŸåç§°ï¼ˆç”¨äºé€‰æ‹©æ•°æ®åº“ï¼Œå¦‚æœæœªæä¾› database_idï¼‰
            database_id: ç›®æ ‡æ•°æ®åº“ IDï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
        
        è¿”å›:
            dict: åŒ…å« success, page_id, title, target_db_id çš„å­—å…¸
        """
        if not draft:
            return {"success": False, "page_id": None}

        title = draft.get("title", "Untitled")
        markdown_body = draft.get("markdown_body") or raw_text[:3000]
        draft["markdown_body"] = markdown_body

        # ç¡®å®šç›®æ ‡æ•°æ®åº“ï¼ˆä¼˜å…ˆä½¿ç”¨ database_idï¼Œå¦åˆ™æ ¹æ® domain é€‰æ‹©ï¼‰
        if database_id:
            target_db = database_id
        elif domain == "spanish_learning":
            target_db = notion_ops.DB_SPANISH_ID
        elif domain == "tech_knowledge":
            target_db = notion_ops.DB_TECH_ID
        else:
            target_db = notion_ops.DB_HUMANITIES_ID

        # æ³¨æ„ï¼šæ–°æµç¨‹ä¸­åˆå¹¶é€»è¾‘åœ¨ workflow.py çš„ node_draft_merge ä¸­å¤„ç†
        # è¿™é‡Œåªå¤„ç†æ–°å»ºé¡µé¢çš„æƒ…å†µ
        # ï¼ˆä¿ç•™ merge é€»è¾‘ä½œä¸ºå‘åå…¼å®¹ï¼Œä½†åœ¨æ–°æµç¨‹ä¸­ memory_match é€šå¸¸ä¸º Noneï¼‰
        page_id = None
        if memory_match and memory_match.get("match") and intent_type != "query_knowledge":
            existing_id = memory_match.get("page_id")
            print(f"ğŸ”— Found related page ({existing_id}). Starting Merge...")
            
            try:
                old_text = notion_ops.get_page_text(existing_id)
                if old_text:
                    merged_draft = self._internal_merge(old_text, draft, intent_type)
                    if merged_draft and merged_draft.get("markdown_body"):
                        success = notion_ops.overwrite_page_content(existing_id, merged_draft)
                        if success:
                            page_id = existing_id
                            print(f"âœ… Merged: {merged_draft.get('title')}")
            except Exception as e:
                print(f"âš ï¸ Merge failed ({e}), creating new page.")

        # åˆ›å»ºæ–°é¡µé¢
        if not page_id:
            page_id = notion_ops.create_general_note(draft, target_db, original_url)

        if not page_id:
            return {"success": False}

        return {
            "success": True,
            "page_id": page_id,
            "title": title,
            "target_db_id": target_db,
        }
        
    def _internal_merge(self, old_text: str, new_draft: dict, intent_type: str) -> dict:
        """
        å†…éƒ¨åˆå¹¶æ–¹æ³•ï¼ˆç”± publish æ–¹æ³•è°ƒç”¨ï¼Œç”¨äºå‘åå…¼å®¹ï¼‰
        
        å‚æ•°:
            old_text: æ—§ç¬”è®°æ–‡æœ¬
            new_draft: æ–°è‰ç¨¿å­—å…¸
            intent_type: æ„å›¾ç±»å‹ï¼ˆæœªä½¿ç”¨ä½†ä¿ç•™å‚æ•°å…¼å®¹æ€§ï¼‰
        
        è¿”å›:
            dict: åˆå¹¶åçš„è‰ç¨¿
        """
        new_text = new_draft.get("markdown_body", "") or str(new_draft)
        prompt = f"""
        Act as a Knowledge Manager. Merge these texts into one article.
        LANGUAGE: SIMPLIFIED CHINESE.
        FORMAT: Markdown.

        --- OLD ---
        {old_text[:6000]}
        
        --- NEW ---
        {new_text[:6000]}
        
        JSON SCHEMA: 
        {{ "title": "str", "summary": "str", "markdown_body": "str" }}
        """
        res, _ = get_reasoning_completion(prompt)
        return safe_json_parse(res, "Merge")