import os
import chromadb
from chromadb.utils import embedding_functions
from dotenv import load_dotenv

load_dotenv()

# --- é…ç½® ---
# æˆ‘ä»¬ä½¿ç”¨ OpenAI çš„ text-embedding-3-small (ä¾¿å®œä¸”å¼ºå¤§)
# å¦‚æœä½ åªç”¨ DeepSeekï¼ŒDeepSeek å¹¶æ²¡æœ‰å®˜æ–¹å…¼å®¹ OpenAI æ ¼å¼çš„ Embedding API (æˆªè‡³ç›®å‰)
# æ‰€ä»¥è¿™é‡Œå»ºè®®å•ç‹¬é…ä¸€ä¸ª OpenAI Keyï¼Œæˆ–è€…ä½¿ç”¨æœ¬åœ°æ¨¡å‹ (SentenceTransformer)
# ä¸ºäº†æ¼”ç¤ºæœ€ç®€ä¾¿çš„æ–¹æ³•ï¼Œæˆ‘ä»¬å‡è®¾ä½ æœ‰ä¸€ä¸ªèƒ½è°ƒç”¨çš„ Embedding æœåŠ¡
# å¦‚æœæ²¡æœ‰ OpenAI Keyï¼Œå¯ä»¥ä½¿ç”¨ chromadb è‡ªå¸¦çš„ default_embedding_function (ä¸‹è½½æœ¬åœ°æ¨¡å‹ï¼Œå…è´¹)

# è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ Chroma é»˜è®¤çš„ SentenceTransformer (å®Œå…¨å…è´¹ï¼Œæœ¬åœ°è¿è¡Œï¼Œä¸ç”¨ API Key)
# ç¬¬ä¸€æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ (çº¦ 80MB)
EMBEDDING_FUNC = embedding_functions.SentenceTransformerEmbeddingFunction(
    model_name="all-MiniLM-L6-v2"
)

# åˆå§‹åŒ–æœ¬åœ°æ•°æ®åº“ (ä¼šåœ¨é¡¹ç›®ç›®å½•ä¸‹ç”Ÿæˆä¸€ä¸ª chromadb æ–‡ä»¶å¤¹)
client = chromadb.PersistentClient(path="./chroma_db")

# åˆ›å»ºæˆ–è·å–é›†åˆ (Collection)
collection = client.get_or_create_collection(
    name="knowledge_base",
    embedding_function=EMBEDDING_FUNC
)

def add_memory(page_id, text_content, title, category):
    """
    å­˜å…¥è®°å¿†ï¼šå°†ç¬”è®°å†…å®¹å‘é‡åŒ–å¹¶å­˜å…¥ Chroma
    """
    print(f"ğŸ’¾ Vectorizing memory: {title}...")
    try:
        collection.add(
            documents=[text_content],       # åŸå§‹å†…å®¹ (ç”¨äºè®¡ç®—å‘é‡)
            metadatas=[{"title": title, "category": category}], # å…ƒæ•°æ®
            ids=[page_id]                   # ä½¿ç”¨ Notion Page ID ä½œä¸ºå”¯ä¸€æ ‡è¯†
        )
        print("âœ… Memory stored in Vector DB.")
        return True
    except Exception as e:
        print(f"âŒ Failed to store vector: {e}")
        return False

def search_memory(query_text, n_results=1):
    """
    æ£€ç´¢è®°å¿†ï¼šå¯»æ‰¾æœ€ç›¸ä¼¼çš„ç¬”è®°
    """
    print(f"ğŸ” Vector Searching for: {query_text[:20]}...")
    try:
        results = collection.query(
            query_texts=[query_text],
            n_results=n_results
        )
        
        # Chroma è¿”å›çš„ç»“æ„æ¯”è¾ƒå¤æ‚ï¼Œæˆ‘ä»¬éœ€è¦è§£åŒ…
        if results['ids'] and results['ids'][0]:
            # è·å–ç›¸ä¼¼åº¦è·ç¦» (Distance)
            # Distance è¶Šå°è¶Šç›¸ä¼¼ã€‚ä¸€èˆ¬ < 0.3 æˆ– 0.4 ç®—éå¸¸ç›¸ä¼¼
            distance = results['distances'][0][0]
            page_id = results['ids'][0][0]
            metadata = results['metadatas'][0][0]
            
            print(f"   Found candidate: {metadata['title']} (Distance: {distance:.4f})")
            
            # è®¾å®šä¸€ä¸ªé˜ˆå€¼ï¼Œå¦‚æœè·ç¦»å¤ªè¿œ(æ¯”å¦‚ > 0.5)ï¼Œè®¤ä¸ºæ˜¯ä¸ç›¸å…³çš„
            if distance < 0.5: 
                return {
                    "match": True,
                    "page_id": page_id,
                    "title": metadata['title'],
                    "distance": distance
                }
            else:
                print("   No close match found (Distance too high).")
                return {"match": False}
        
        return {"match": False}
    except Exception as e:
        print(f"âŒ Vector Search Error: {e}")
        return {"match": False}

# --- åˆå§‹åŒ–è„šæœ¬ (å¯é€‰) ---
# å¦‚æœä½ æƒ³æŠŠ Notion é‡Œç°æœ‰çš„ç¬”è®°åŒæ­¥è¿‡æ¥ï¼Œéœ€è¦å†™ä¸€ä¸ªä¸€æ¬¡æ€§è„šæœ¬
# è¿™é‡Œæš‚ç•¥ï¼Œå…ˆä¿è¯æ–°ç¬”è®°èƒ½å­˜è¿›å»