import os
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()

client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    base_url=os.getenv("OPENAI_BASE_URL")
)

def get_completion(prompt, model="deepseek-chat"):
    """
    é€šç”¨å¿«é€Ÿæ¨¡å¼ (DeepSeek-V3)
    """
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1, 
            stream=False,
            max_tokens=8000  # ğŸ”¼ å¢åŠ è¾“å‡ºä¸Šé™ï¼Œé˜²æ­¢é•¿æ–‡æˆªæ–­
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"âŒ V3 è°ƒç”¨å¤±è´¥: {e}")
        return ""

def get_reasoning_completion(prompt):
    """
    æ·±åº¦æ€è€ƒæ¨¡å¼ (DeepSeek-R1)
    """
    try:
        print("ğŸ¤” R1 æ­£åœ¨æ·±åº¦æ€è€ƒ (è¿™å¯èƒ½éœ€è¦ä¸€ç‚¹æ—¶é—´)...")
        response = client.chat.completions.create(
            model="deepseek-reasoner", 
            messages=[{"role": "user", "content": prompt}],
            max_tokens=8000  # ğŸ”¼ å…³é”®ï¼ç»™æ€è€ƒè¿‡ç¨‹å’Œ JSON ç•™è¶³ç©ºé—´
        )
        
        # è·å–æœ€ç»ˆå›ç­”
        content = response.choices[0].message.content
        
        # è·å–æ€è€ƒè¿‡ç¨‹
        reasoning = getattr(response.choices[0].message, 'reasoning_content', None)
        
        if not reasoning:
            reasoning = "ï¼ˆæ¨¡å‹æœªè¿”å›æ˜¾å¼æ€è€ƒè¿‡ç¨‹ï¼‰"
            
        return content, reasoning
        
    except Exception as e:
        print(f"âŒ R1 è°ƒç”¨å¤±è´¥: {e}")
        # å¦‚æœ R1 æŒ‚äº†ï¼Œé™çº§ç”¨ V3
        return get_completion(prompt), "ï¼ˆé™çº§ä¸º V3ï¼Œæ— æ€è€ƒè¿‡ç¨‹ï¼‰"
