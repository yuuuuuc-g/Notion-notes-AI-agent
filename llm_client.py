import os
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()

client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    base_url=os.getenv("OPENAI_BASE_URL")
)

def get_completion(prompt, model="deepseek-chat"):
    """
    é€šç”¨å¿«é€Ÿæ¨¡å¼ (DeepSeek-V3)
    ç”¨äºï¼šåˆ†ç±»ã€ç®€å•æå–ã€JSONæ ¼å¼åŒ–
    """
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1, 
            stream=False,
            # V3 ä¸éœ€è¦æ€è€ƒï¼Œ8192 è¶³å¤Ÿå†™å‡ºéå¸¸é•¿çš„ JSON
            max_tokens=8192 
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"âŒ V3 è°ƒç”¨å¤±è´¥: {e}")
        return ""

def get_reasoning_completion(prompt):
    """
    æ·±åº¦æ€è€ƒæ¨¡å¼ (DeepSeek-R1)
    """
    try:
        print("ğŸ¤” R1 æ­£åœ¨æ·±åº¦æ€è€ƒ (Deep Thinking)...")
        # æ³¨æ„ï¼šDeepSeek çš„ reasoning è¿‡ç¨‹æ˜¯è®¡å…¥è¾“å‡º token çš„
        # æˆ‘ä»¬å¿…é¡»æŠŠå®ƒæ‹‰åˆ°æœ€å¤§ï¼Œé˜²æ­¢æ€è€ƒå¤ªä¹…å¯¼è‡´ JSON æ²¡å†™å®Œ
        response = client.chat.completions.create(
            model="deepseek-reasoner", 
            messages=[{"role": "user", "content": prompt}],
            max_tokens=8192  # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šæ‹‰æ»¡åˆ° 8k
        )
        
        # è·å–æœ€ç»ˆå›ç­”
        content = response.choices[0].message.content
        
        # è·å–æ€è€ƒè¿‡ç¨‹
        reasoning = getattr(response.choices[0].message, 'reasoning_content', None)
        
        if not reasoning:
            reasoning = "ï¼ˆæ¨¡å‹æœªè¿”å›æ˜¾å¼æ€è€ƒè¿‡ç¨‹ï¼‰"
            
        return content, reasoning
        
    except Exception as e:
        print(f"âŒ R1 è°ƒç”¨å¤±è´¥: {e}")
        # å¦‚æœ R1 è¿˜æ˜¯ä¸è¡Œï¼Œè‡ªåŠ¨é™çº§ç”¨ V3 (V3 ä¸æ€è€ƒç›´æ¥å†™ï¼Œåè€Œä¸å®¹æ˜“æˆªæ–­)
        print("ğŸ”„ å°è¯•é™çº§ä½¿ç”¨ DeepSeek-V3...")
        return get_completion(prompt), "ï¼ˆé™çº§ä¸º V3ï¼Œæ— æ€è€ƒè¿‡ç¨‹ï¼‰"
