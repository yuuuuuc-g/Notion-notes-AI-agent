import os
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()

client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    base_url=os.getenv("OPENAI_BASE_URL")
)

def get_completion(prompt, model="deepseek-chat"):
    """
    é€šç”¨å¿«é€Ÿæ¨¡å¼ (DeepSeek-V3)
    ç”¨äºï¼šåˆ†ç±»ã€ç®€å•æå–ã€JSONæ ¼å¼åŒ–
    """
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1, 
            stream=False
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"âŒ V3 è°ƒç”¨å¤±è´¥: {e}")
        return ""

def get_reasoning_completion(prompt):
    """
    æ·±åº¦æ€è€ƒæ¨¡å¼ (DeepSeek-R1)
    ç”¨äºï¼šé•¿éš¾æ–‡ç« åˆ†æã€å¤æ‚é€»è¾‘åˆ¤æ–­ã€è¥¿è¯­æ·±åº¦è§£æ
    è¿”å›: (content, reasoning_content) å…ƒç»„
    """
    try:
        print("ğŸ¤” R1 æ­£åœ¨æ·±åº¦æ€è€ƒ (Deep Thinking)...")
        response = client.chat.completions.create(
            model="deepseek-reasoner", 
            messages=[{"role": "user", "content": prompt}],
            # R1 ä¸æ”¯æŒ temperature å‚æ•° (æˆ–å»ºè®®è®¾ä¸ºé»˜è®¤)
        )
        
        # è·å–æœ€ç»ˆå›ç­”
        content = response.choices[0].message.content
        
        # è·å–æ€è€ƒè¿‡ç¨‹
        reasoning = getattr(response.choices[0].message, 'reasoning_content', None)
        
        if not reasoning:
            reasoning = "ï¼ˆæ¨¡å‹æœªè¿”å›æ˜¾å¼æ€è€ƒè¿‡ç¨‹ï¼‰"
            
        return content, reasoning
        
    except Exception as e:
        print(f"âŒ R1 è°ƒç”¨å¤±è´¥: {e}")
        # å¦‚æœ R1 æŒ‚äº†ï¼Œé™çº§ç”¨ V3
        return get_completion(prompt), "ï¼ˆé™çº§ä¸º V3ï¼Œæ— æ€è€ƒè¿‡ç¨‹ï¼‰"