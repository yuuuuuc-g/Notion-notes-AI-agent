from typing import TypedDict, Dict, Any, Optional
from enum import Enum

from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from pydantic import BaseModel, ValidationError

from agents import ResearcherAgent, EditorAgent
import notion_ops
import vector_ops

# =========================================================
# Init Agents
# =========================================================
researcher = ResearcherAgent()
editor = EditorAgent()


# =========================================================
# Knowledge Domain
# =========================================================
class KnowledgeDomain(str, Enum):
    SPANISH = "spanish_learning"
    TECH = "tech_knowledge"
    HUMANITIES = "humanities"


INTENT_TO_DOMAIN = {
    "Spanish": KnowledgeDomain.SPANISH,
    "Tech": KnowledgeDomain.TECH,
    "Humanities": KnowledgeDomain.HUMANITIES,
}


# =========================================================
# State Definition
# =========================================================
class AgentState(TypedDict, total=False):
    # Input
    user_input: str
    uploaded_file: Optional[Any]

    # Parsed content
    raw_text: str
    original_url: str

    # Analysis
    intent_type: str
    knowledge_domain: KnowledgeDomain

    # Memory
    memory_match: Dict

    # Draft
    draft: Dict
    retry_count: int
    error_message: str

    # Human review
    human_feedback: str
    override_database_id: str
    notion_database_id: str

    # Publish result
    published_page_id: str
    published_title: str
    final_output: str


def default_state() -> dict:
    return {
        "user_input": "",
        "uploaded_file": None,
        "raw_text": "",
        "original_url": "",
        "intent_type": "",
        "knowledge_domain": None,
        "memory_match": {},
        "draft": {},
        "retry_count": 0,
        "error_message": "",
        "human_feedback": "",
        "override_database_id": "",
        "notion_database_id": "",
        "final_output": "",
    }


# =========================================================
# Draft Validation
# =========================================================
class DraftSchema(BaseModel):
    title: str
    summary: str


# =========================================================
# Nodes
# =========================================================
def node_memory_saver(state: AgentState) -> AgentState:
    print("ğŸ’¾ [Graph] Saving to Memory...")
    
    # åªæœ‰å‘å¸ƒæˆåŠŸæ‰ä¿å­˜
    if state.get("published_page_id"):
        # å°†æœ€ç»ˆç¡®å®šçš„æ ‡é¢˜å’Œå†…å®¹å­˜å…¥å‘é‡åº“
        vector_ops.add_memory(
            page_id=state["published_page_id"],
            content=state["raw_text"], # æˆ–è€…å­˜ summaryï¼Œå–å†³äºä½ æƒ³æŸ¥é‡çš„ç²’åº¦
            title=state["draft"].get("title", "Untitled"),
            category=state["knowledge_domain"].value,
            metadata={
                "url": state.get("original_url", ""),
                "type": state.get("intent_type", "")
            }
        )
        return {"final_output": state["final_output"] + " (Saved to Memory)"}
    return {}

def node_perceiver(state: AgentState) -> AgentState:
    print("ğŸ”µ [Graph] Perceiver...")
    raw_text = (state.get("raw_text") or "").strip()

    if not raw_text:
        raise ValueError("Perceiver requires pre-processed raw_text")

    return {
        "raw_text": raw_text,
        "original_url": state.get("original_url", ""),
    }


def node_classifier(state: AgentState) -> AgentState:
    print("ğŸ”µ [Graph] Classifier...")
    result = researcher.analyze_intent(state["raw_text"])
    return {"intent_type": result.get("type", "Humanities")}


def node_domain_router(state: AgentState) -> AgentState:
    intent = state.get("intent_type", "Humanities")
    domain = INTENT_TO_DOMAIN.get(intent, KnowledgeDomain.HUMANITIES)

    db_map = {
        KnowledgeDomain.SPANISH: notion_ops.DB_SPANISH_ID,
        KnowledgeDomain.TECH: notion_ops.DB_TECH_ID,
        KnowledgeDomain.HUMANITIES: notion_ops.DB_HUMANITIES_ID,
    }

    return {
        "knowledge_domain": domain,
        "notion_database_id": db_map.get(domain),
    }


def node_memory(state: AgentState) -> AgentState:
    domain = state["knowledge_domain"]
    print(f"ğŸ”µ [Graph] Memory (Domain={domain.value})...")
    match = researcher.consult_memory(
        state["raw_text"],
        domain=domain.value,
    )
    return {"memory_match": match}


def node_researcher(state: AgentState) -> AgentState:
    print(f"ğŸ”µ [Graph] Researcher (Attempt {state.get('retry_count', 0) + 1})...")
    draft = researcher.draft_content(
        state["raw_text"],
        state["intent_type"],
        error_context=state.get("error_message", ""),
    )
    return {"draft": draft}


def node_validator(state: AgentState) -> AgentState:
    print("ğŸ”µ [Graph] Validator...")
    try:
        DraftSchema(
            title=state["draft"].get("title"),
            summary=state["draft"].get("summary"),
        )
        return {"error_message": ""}
    except ValidationError as e:
        print("âŒ Validation failed:", e)
        return {
            "error_message": str(e),
            "retry_count": state.get("retry_count", 0) + 1,
        }


def node_human_review(state: AgentState) -> AgentState:
    print("ğŸŸ  [Graph] Human Review...")
    if state.get("override_database_id"):
        return {"notion_database_id": state["override_database_id"]}
    return {}


def node_publisher(state: AgentState) -> AgentState:
    """
    Returns:
    {
    "success": bool,
    "page_id": str | None,
    "target_db_id": str | None,
    }
    """
    print("ğŸ”µ [Graph] Publisher...")

    result = editor.publish(
        draft=state["draft"],
        intent_type=state["intent_type"],
        memory_match=state["memory_match"],
        raw_text=state["raw_text"],
        original_url=state.get("original_url"),
        database_id=state.get("notion_database_id"),
        domain=state["knowledge_domain"].value,
    )

    if not result["success"]:
        return {"final_output": "âŒ Publish failed"}

    return {
        "published_page_id": result["page_id"],
        "published_title": result["title"],
        "final_output": "âœ… Published",
    }


# =========================================================
# Routing
# =========================================================
def route_after_validation(state: AgentState):
    if not state.get("error_message"):
        return "human_review"
    if state.get("retry_count", 0) <= 2:
        return "researcher"
    return "human_review"


# =========================================================
# Graph Build
# =========================================================
workflow = StateGraph(AgentState)

workflow.add_node("perceiver", node_perceiver)
workflow.add_node("classifier", node_classifier)
workflow.add_node("domain_router", node_domain_router)
workflow.add_node("memory", node_memory)
workflow.add_node("researcher", node_researcher)
workflow.add_node("validator", node_validator)
workflow.add_node("human_review", node_human_review)
workflow.add_node("publisher", node_publisher)

workflow.set_entry_point("perceiver")
workflow.add_edge("perceiver", "classifier")
workflow.add_edge("classifier", "domain_router")
workflow.add_edge("domain_router", "memory")
workflow.add_edge("memory", "researcher")
workflow.add_edge("researcher", "validator")
workflow.add_conditional_edges(
    "validator",
    route_after_validation,
    {"human_review": "human_review", "researcher": "researcher"},
)
workflow.add_edge("human_review", "publisher")
workflow.add_node("saver", node_memory_saver)
workflow.add_edge("publisher", "saver")
workflow.add_edge("saver", END)

checkpointer = MemorySaver()
app_graph = workflow.compile(
    checkpointer=checkpointer,
    interrupt_before=["human_review"],
)

# ç¼–è¯‘å›¾
app = workflow.compile()

# ==========================================
# ğŸ”¥ 5. æœ¬åœ°è¿è¡Œå…¥å£ (CLI Entry Point) 
# ==========================================
if __name__ == "__main__":
    import sys
    import os
    
    # --- 1. è¯»å– txt æ–‡ä»¶é€»è¾‘ (ä¿æŒä¸å˜) ---
    TEST_FILE_NAME = "test_input.txt"
    print(f"ğŸš€ Starting Local Graph Test...")

    if os.path.exists(TEST_FILE_NAME):
        try:
            with open(TEST_FILE_NAME, "r", encoding="utf-8") as f:
                test_input = f.read().strip()
            if not test_input:
                test_input = "ä»€ä¹ˆæ˜¯æ‰¹åˆ¤æ€§æ€ç»´ï¼Ÿ" 
            else:
                print(f"ğŸ“‚ æˆåŠŸè¯»å–æ–‡ä»¶: {TEST_FILE_NAME}")
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶å‡ºé”™: {e}")
            test_input = "Error."
    else:
        # è‡ªåŠ¨åˆ›å»ºæ–‡ä»¶æ–¹ä¾¿ä¸‹æ¬¡ç”¨
        with open(TEST_FILE_NAME, "w", encoding="utf-8") as f:
            f.write("åœ¨è¿™é‡Œç²˜è´´ä½ æƒ³æµ‹è¯•çš„å†…å®¹...")
        test_input = "åœ¨è¿™é‡Œç²˜è´´ä½ æƒ³æµ‹è¯•çš„å†…å®¹..."

    print("-" * 50)

    # --- 2. æ„é€ åˆå§‹çŠ¶æ€ (ğŸ”´ å…³é”®ä¿®æ”¹åœ¨è¿™é‡Œ) ---
    initial_state = {
        "user_input": test_input,
        
        # âœ… è¿™é‡Œå¿…é¡»æ‰‹åŠ¨åŠ ä¸Š raw_textï¼
        # å› ä¸º Streamlit åœ¨è°ƒç”¨å‰å¸®ä½ åŠ äº†ï¼Œä½†åœ¨æœ¬åœ°æˆ‘ä»¬å¾—è‡ªå·±åŠ ã€‚
        "raw_text": test_input,  
        
        "file_path": None,
        "intent": {}, # æ³¨æ„ï¼šä½ çš„ State å®šä¹‰é‡Œå¥½åƒå« intent_typeï¼Œè¿™é‡Œå…¶å®å¯ä»¥ç•™ç©ºï¼ŒClassifier ä¼šå¡«å……
        "intent_type": "", # åˆå§‹åŒ–ä¸ºç©º
        "knowledge_domain": None,
        "memory_match": {},
        "draft": {},
        "retry_count": 0,
        "error_message": "",
        "human_feedback": "",
        "override_database_id": "",
        "notion_database_id": "",
        "final_output": "",
        "original_url": ""
    }

    # --- 3. è¿è¡Œå›¾ (.invoke) ---
    try:
        # ä½¿ç”¨ä½ ä»£ç é‡Œå·²ç» compile å¥½çš„ app å˜é‡
        final_state = app.invoke(initial_state)
        
        # --- 4. æ‰“å°ç»“æœ ---
        print("\n" + "="*50)
        print("âœ… Workflow Completed!")
        print("="*50)
        
        # è¿™é‡Œæ‰“å° final_output å­—ç¬¦ä¸²ï¼Œæˆ–è€…å…¶ä»–ä½ æƒ³çœ‹çš„å­—æ®µ
        print(f"Result: {final_state.get('final_output')}")
        
        if final_state.get("published_page_id"):
             print(f"ğŸ‰ Page ID: {final_state.get('published_page_id')}")
             print(f"ğŸ”— Title: {final_state.get('published_title')}")

    except Exception as e:
        print(f"\nâŒ Graph Execution Error: {e}")
        # æ‰“å°è¯¦ç»†é”™è¯¯å †æ ˆä»¥ä¾¿è°ƒè¯•
        import traceback
        traceback.print_exc()