from typing import TypedDict
from enum import Enum

from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

from agents import ResearcherAgent, EditorAgent
import notion_ops
import vector_ops

# Initialize agent instances
researcher = ResearcherAgent()
editor = EditorAgent()

# =========================================================
# State Definitions
# =========================================================

class KnowledgeDomain(str, Enum):
    SPANISH = "spanish_learning"
    TECH = "tech_knowledge"
    HUMANITIES = "humanities"


INTENT_TO_DOMAIN = {
    "Spanish": KnowledgeDomain.SPANISH,
    "Tech": KnowledgeDomain.TECH,
    "Humanities": KnowledgeDomain.HUMANITIES,
}


class AnalysisState(TypedDict, total=False):
    intent_type: str        # query_knowledge | save_note
    category: str           # Spanish | Tech | Humanities (åŸå§‹åˆ†ç±»)
    domain: KnowledgeDomain # æ˜ å°„åçš„é¢†åŸŸæšä¸¾
    routing: str            # query | save
    confidence: float


class DraftState(TypedDict, total=False):
    title: str
    summary: str
    content: str
    tags: list[str]
    is_merge: bool          
    merge_target_id: str    
    

class MemoryState(TypedDict, total=False):
    query_results: dict
    write_payload: dict


class AgentState(TypedDict, total=False):
    # Input
    user_input: str
    raw_text: str
    original_url: str

    # Core States
    analysis: AnalysisState
    draft: DraftState
    memory: MemoryState

    # Meta
    retry_count: int
    error_message: str

    # Output
    final_output: str
    published_page_id: str


# =========================================================
# Nodes
# =========================================================

def node_memory_saver(state: AgentState) -> AgentState:
    """
    è®°å¿†ä¿å­˜èŠ‚ç‚¹ï¼šå°†å·²å‘å¸ƒçš„é¡µé¢ä¿å­˜åˆ°å‘é‡æ•°æ®åº“ï¼Œä¾¿äºåç»­æ£€ç´¢
    """
    print("ğŸ’¾ [Graph] Saving to Memory...")
    
    # æå–æ ‡é¢˜å’Œæ‘˜è¦ï¼ˆä¼˜å…ˆä»è‰ç¨¿ä¸­è·å–ï¼‰
    title = "Untitled"
    summary = ""
    
    if state.get("draft"):
        title = state["draft"].get("title", "Untitled")
        summary = state["draft"].get("summary", "No summary provided.")

    # åªæœ‰å½“é¡µé¢å·²å‘å¸ƒæ—¶ï¼Œæ‰ä¿å­˜åˆ°è®°å¿†åº“
    if state.get("published_page_id"):
        vector_ops.add_memory(
            page_id=state["published_page_id"],
            content=state["raw_text"],
            title=title,
            category=state["analysis"]["domain"].value,
            metadata={
                "url": state.get("original_url", ""),
                "type": state["analysis"].get("intent_type", ""),
                "summary": summary  # å°†æ‘˜è¦å­˜å…¥å…ƒæ•°æ®ï¼Œä¾›æŸ¥è¯¢æ—¶ä½¿ç”¨
            }
        )
        return {"final_output": state.get("final_output", "") + "\n(Saved to Memory)"}
    return {}


def node_recall_context(state: AgentState) -> AgentState:
    """
    é€šç”¨å¬å›èŠ‚ç‚¹ï¼šæ— è®ºæ˜¯å›ç­”é—®é¢˜è¿˜æ˜¯å†™ç¬”è®°ï¼Œéƒ½å…ˆçœ‹çœ‹è®°å¿†åº“é‡Œæœ‰ä»€ä¹ˆ
    """
    print("ğŸ” [Recall] Checking Memory...")
    # å¼ºåˆ¶å…¨åº“æœç´¢ï¼Œæ‰¾å‡ºæœ€ç›¸å…³çš„ç¬”è®°
    results = researcher.consult_memory(state["raw_text"], domain="All")
    
    return {
        "memory": {"query_results": results}
    }

def route_after_recall(state: AgentState):
    """
    æ£€ç´¢åçš„åˆ†æµï¼š
    1. å¦‚æœæ˜¯æé—® (query) -> å»å›ç­”
    2. å¦‚æœæ˜¯ä¿å­˜ (save) ä¸”æ‰¾åˆ°ç›¸å…³ç¬”è®° -> å»èåˆ (Merge)
    3. å¦‚æœæ˜¯ä¿å­˜ (save) ä¸”æ— ç›¸å…³ç¬”è®° -> å»æ–°å»º (Draft)
    """
    intent = state["analysis"]["intent_type"]
    memory_match = state["memory"].get("query_results", {}).get("match", False)

    print(f"ğŸ”€ [Router] Intent: {intent}, Memory Match: {memory_match}")

    if intent == "query_knowledge":
        return "generate_answer"
    elif intent == "save_note" and memory_match:
        return "merge_draft"
    else:
        return "new_draft"
    
    
def node_perceiver(state: AgentState) -> AgentState:
    """
    æ„ŸçŸ¥èŠ‚ç‚¹ï¼šé¢„å¤„ç†è¾“å…¥ï¼Œç»Ÿä¸€æå– raw_text å’Œ original_url
    è¿™æ˜¯å·¥ä½œæµçš„å…¥å£èŠ‚ç‚¹ï¼Œè´Ÿè´£æ•°æ®æ¸…æ´—å’Œæ ‡å‡†åŒ–
    """
    print("ğŸ”µ [Graph] Perceiver...")
    raw_text = (state.get("raw_text") or state.get("user_input") or "").strip()

    if not raw_text:
        raise ValueError("Perceiver requires pre-processed raw_text")

    return {
        "raw_text": raw_text,
        "original_url": state.get("original_url", ""),
    }


def node_analyzer(state: AgentState) -> AgentState:
    """
    åˆ†æèŠ‚ç‚¹ï¼šåˆ†æç”¨æˆ·æ„å›¾å’ŒçŸ¥è¯†é¢†åŸŸ
    è¾“å‡º intent_type (query_knowledge/save_note)ã€category (Spanish/Tech/Humanities) å’Œå¯¹åº”çš„ domain
    """
    print("ğŸ§  [Analysis] Intent & Domain Detection")

    result = researcher.analyze_intent(state["raw_text"])

    # å…¼å®¹å¤„ç†ï¼šç¡®ä¿å­—æ®µå­˜åœ¨
    intent = result.get("intent", "save_note")
    # å¦‚æœ analyze_intent è¿”å›çš„æ˜¯ "save_note" æˆ– "query_knowledge"ï¼Œéœ€è¦åšä¸€ä¸‹æ˜ å°„
    if "query" in intent:
        routing = "query"
    else:
        routing = "save"
        
    category = result.get("category", "Humanities")
    domain = INTENT_TO_DOMAIN.get(category, KnowledgeDomain.HUMANITIES)

    print(f"   -> Intent: {intent}, Category: {category}, Domain: {domain.value}")

    return {
        "analysis": {
            "intent_type": intent,
            "category": category,  # ä¿å­˜åŸå§‹åˆ†ç±»ï¼Œä¾› draft_content ä½¿ç”¨
            "domain": domain,
            "routing": routing,
            "confidence": result.get("confidence", 0.7),
        }
    }


def node_query_memory(state: AgentState) -> AgentState:
    """
    æŸ¥è¯¢è®°å¿†èŠ‚ç‚¹ï¼šæ ¼å¼åŒ–å¹¶è¾“å‡ºè®°å¿†åº“æŸ¥è¯¢ç»“æœ
    æ³¨æ„ï¼šå¤ç”¨ recall_context èŠ‚ç‚¹çš„æŸ¥è¯¢ç»“æœï¼Œé¿å…é‡å¤æŸ¥è¯¢
    """
    print("ğŸ” [Query] Formatting Memory Search Results")

    # å¤ç”¨ recall_context èŠ‚ç‚¹çš„æŸ¥è¯¢ç»“æœï¼Œé¿å…é‡å¤æŸ¥è¯¢
    results = state.get("memory", {}).get("query_results", {})
    
    # å¦‚æœæ²¡æœ‰ç»“æœï¼ˆç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿï¼‰ï¼Œåˆ™è¿›è¡Œä¸€æ¬¡æŸ¥è¯¢ä½œä¸ºå…œåº•
    if not results:
        print("âš ï¸ [Query] No cached results, performing search...")
        results = researcher.consult_memory(state["raw_text"], domain="All")

    # æ ¼å¼åŒ–è¾“å‡ºæŸ¥è¯¢ç»“æœ
    if results.get("match"):
        # æ„é€  Notion é“¾æ¥
        page_id = results["page_id"].replace("-", "")
        notion_url = f"https://www.notion.so/{page_id}"
        
        title = results.get("title", "Untitled")
        # ä» metadata ä¸­æå–æ‘˜è¦ (å¦‚æœæ—§æ•°æ®æ²¡æœ‰æ‘˜è¦ï¼Œæä¾›é»˜è®¤æ–‡æ¡ˆ)
        summary = results.get("metadata", {}).get("summary", "ï¼ˆè¯¥ç¬”è®°æš‚æ— æ‘˜è¦å…ƒæ•°æ®ï¼‰")
        
        # ğŸ¯ ç®€æ´çš„å¡ç‰‡å¼è¾“å‡º
        final_output = (
            f"âœ… **å·²æ‰¾åˆ°ç›¸å…³ç¬”è®°**\n\n"
            f"ğŸ“„ **[{title}]({notion_url})**\n\n"
            f"ğŸ’¡ **æ‘˜è¦**ï¼š\n{summary}"
        )
    else:
        final_output = "âŒ æœªåœ¨çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ç›¸å…³æ–‡ç« ã€‚"

    return {
        "memory": {"query_results": results},
        "final_output": final_output
    }


def node_draft_new(state: AgentState) -> AgentState:
    """
    æ–°å»ºè‰ç¨¿èŠ‚ç‚¹ï¼šæ ¹æ®åŸå§‹æ–‡æœ¬åˆ›å»ºæ–°çš„ç¬”è®°è‰ç¨¿
    ä½¿ç”¨ ResearcherAgent çš„ draft_content æ–¹æ³•ç”Ÿæˆç»“æ„åŒ–å†…å®¹
    """
    print("âœï¸ [Draft] Creating New Note")
    # draft_content éœ€è¦ category (Spanish/Tech/Humanities) ä½œä¸ºç¬¬äºŒä¸ªå‚æ•°
    category = state["analysis"].get("category", "Humanities")
    draft = researcher.draft_content(
        state["raw_text"],
        category
    )
    return {"draft": draft}


def node_draft_merge(state: AgentState) -> AgentState:
    """
    åˆå¹¶è‰ç¨¿èŠ‚ç‚¹ï¼šå°†æ–°å†…å®¹ä¸ç°æœ‰ç¬”è®°åˆå¹¶
    """
    print("âš—ï¸ [Merge] Merging with Existing Note")
    existing_note = state["memory"]["query_results"]
    
    # è·å–æ—§ç¬”è®°å…¨æ–‡ (éœ€è¦è°ƒç”¨ notion_ops è·å–è¯¦æƒ…ï¼Œå› ä¸ºå‘é‡åº“é‡Œåªæœ‰ç‰‡æ®µ)
    old_content = notion_ops.get_page_text(existing_note["page_id"])
    
    # è°ƒç”¨ Researcher çš„ merge_content æ–¹æ³•è¿›è¡Œå†…å®¹èåˆ
    merged_draft = researcher.merge_content(old_content, state["raw_text"])
    
    merged_draft["is_merge"] = True
    merged_draft["merge_target_id"] = existing_note["page_id"]
    
    return {"draft": merged_draft}

def node_publisher(state: AgentState) -> AgentState:
    """
    å‘å¸ƒèŠ‚ç‚¹ï¼šå°†è‰ç¨¿å‘å¸ƒåˆ° Notion å¯¹åº”çš„æ•°æ®åº“
    """
    print("ğŸ“° [Publish] Publishing to Notion")
    
    current_domain = state["analysis"]["domain"]

    # æ ¹æ®é¢†åŸŸåŠ¨æ€é€‰æ‹©ç›®æ ‡æ•°æ®åº“
    db_map = {
        KnowledgeDomain.SPANISH: notion_ops.DB_SPANISH_ID,
        KnowledgeDomain.TECH: notion_ops.DB_TECH_ID,
        KnowledgeDomain.HUMANITIES: notion_ops.DB_HUMANITIES_ID,
    }
    target_db_id = db_map.get(current_domain, notion_ops.DB_HUMANITIES_ID)

    result = editor.publish(
        draft=state["draft"],
        intent_type=state["analysis"]["intent_type"],
        memory_match=None,  # æ–°æµç¨‹ä¸­è®°å¿†åŒ¹é…åœ¨ recall_context èŠ‚ç‚¹å¤„ç†ï¼Œpublisher ä¸å†éœ€è¦
        raw_text=state["raw_text"],
        original_url=state.get("original_url"),
        database_id=target_db_id,  # ä½¿ç”¨æ˜ å°„åçš„ ID
        domain=current_domain.value,
    )

    if not result.get("success"):
        return {"final_output": "âŒ å‘å¸ƒå¤±è´¥"}

    return {
        "published_page_id": result["page_id"],
        "final_output": f"âœ… å·²å‘å¸ƒåˆ° Notion ({current_domain.value})"
    }


# =========================================================
# Graph Build
# =========================================================
workflow = StateGraph(AgentState)

# æ³¨å†Œæ‰€æœ‰èŠ‚ç‚¹
workflow.add_node("perceiver", node_perceiver)
workflow.add_node("analyzer", node_analyzer)
workflow.add_node("query_memory", node_query_memory)
workflow.add_node("recall_context", node_recall_context)
workflow.add_node("draft_new", node_draft_new)
workflow.add_node("draft_merge", node_draft_merge)  # åˆå¹¶è‰ç¨¿èŠ‚ç‚¹
workflow.add_node("publisher", node_publisher)
workflow.add_node("memory_saver", node_memory_saver)

# è®¾ç½®å…¥å£ç‚¹
workflow.set_entry_point("perceiver")

# å®šä¹‰è¾¹ï¼šå¿…é¡»åœ¨ç¼–è¯‘ä¹‹å‰å®Œæˆæ‰€æœ‰è¾¹çš„æ·»åŠ 
workflow.add_edge("perceiver", "analyzer")
workflow.add_edge("analyzer", "recall_context")  # åˆ†æåå…ˆå»æ£€ç´¢è®°å¿†åº“

# æ¡ä»¶è·¯ç”±ï¼šæ ¹æ®æ„å›¾å’Œè®°å¿†åŒ¹é…ç»“æœå†³å®šä¸‹ä¸€æ­¥
workflow.add_conditional_edges(
    "recall_context",
    route_after_recall,
    {
        "generate_answer": "query_memory",  # æŸ¥è¯¢æ„å›¾ -> æŸ¥è¯¢è®°å¿†èŠ‚ç‚¹
        "merge_draft": "draft_merge",       # ä¿å­˜æ„å›¾ + æ‰¾åˆ°ç›¸å…³ç¬”è®° -> åˆå¹¶è‰ç¨¿
        "new_draft": "draft_new"            # ä¿å­˜æ„å›¾ + æ— ç›¸å…³ç¬”è®° -> æ–°å»ºè‰ç¨¿
    }
)

# è‰ç¨¿åˆ›å»ºè·¯å¾„ï¼šéƒ½æŒ‡å‘å‘å¸ƒèŠ‚ç‚¹
workflow.add_edge("draft_new", "publisher")
workflow.add_edge("draft_merge", "publisher")

# å‘å¸ƒåä¿å­˜åˆ°è®°å¿†åº“
workflow.add_edge("publisher", "memory_saver")

# æŸ¥è¯¢è·¯å¾„å’Œä¿å­˜è·¯å¾„çš„ç»ˆç‚¹
workflow.add_edge("query_memory", END)      # æŸ¥è¯¢å®Œæˆç›´æ¥ç»“æŸ
workflow.add_edge("memory_saver", END)      # ä¿å­˜å®Œæˆåç»“æŸ

# ç¼–è¯‘å¸¦æ£€æŸ¥ç‚¹çš„å›¾ï¼ˆç”¨äº Streamlitï¼Œæ”¯æŒä¸­æ–­å’Œæ¢å¤ï¼‰
checkpointer = MemorySaver()
app_graph = workflow.compile(
    checkpointer=checkpointer,
    interrupt_before=["publisher"]  # åœ¨å‘å¸ƒå‰æš‚åœï¼Œç­‰å¾…äººå·¥å®¡æŸ¥
)

# ç”¨äº CLI çš„æ— çŠ¶æ€ç‰ˆæœ¬ï¼ˆæ— æ£€æŸ¥ç‚¹ï¼Œè¿ç»­æ‰§è¡Œï¼‰
app = workflow.compile()

# ==========================================
# æœ¬åœ°è¿è¡Œå…¥å£ (CLI Entry Point)
# ==========================================
if __name__ == "__main__":
    import os
    
    TEST_FILE_NAME = "test_input.txt"
    print(f"ğŸš€ Starting Local Graph Test...")

    if os.path.exists(TEST_FILE_NAME):
        try:
            with open(TEST_FILE_NAME, "r", encoding="utf-8") as f:
                test_input = f.read().strip()
            if not test_input:
                test_input = "ä»€ä¹ˆæ˜¯æ‰¹åˆ¤æ€§æ€ç»´ï¼Ÿ" 
            else:
                print(f"ğŸ“‚ æˆåŠŸè¯»å–æ–‡ä»¶: {TEST_FILE_NAME}")
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶å‡ºé”™: {e}")
            test_input = "Error."
    else:
        with open(TEST_FILE_NAME, "w", encoding="utf-8") as f:
            f.write("åœ¨è¿™é‡Œç²˜è´´ä½ æƒ³æµ‹è¯•çš„å†…å®¹...")
        test_input = "ä»€ä¹ˆæ˜¯ç»æµç§Ÿï¼Ÿ"

    print("-" * 50)

    # æ„é€ åˆå§‹çŠ¶æ€
    initial_state = {
        "user_input": test_input,
        "raw_text": test_input,
        "analysis": {},
        "draft": {},
        "memory": {},
        "final_output": "",
    }

    try:
        final_state = app.invoke(initial_state)
        
        print("\n" + "="*50)
        print("âœ… Workflow Completed!")
        print("="*50)
        
        print(f"ğŸ“ Final Output:\n{final_state.get('final_output')}")
        
        if final_state.get("published_page_id"):
             print(f"ğŸ‰ Page ID: {final_state.get('published_page_id')}")

    except Exception as e:
        print(f"\nâŒ Graph Execution Error: {e}")
        import traceback
        traceback.print_exc()